<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> How LLMs Are Getting Better and Better: Key Drivers of Progress | Ashish Sinha </title> <meta name="author" content="Ashish Sinha"> <meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. "> <meta name="keywords" content="ashish, sinha, researcher, computer-vision, machine-learning, iit, iit-roorkee, medical-imaging, ai, sfu, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="/assets/libs/mdb/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="/assets/libs/google_fonts/google-fonts.css"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%AA%82&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://sinashish.github.io/blog/2025/llms-are-getting-better/"> <script src="/assets/js/theme.js?a81d82887dd692e91686b43de4542f18"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Ashish</span> Sinha </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <p>Large Language Models (LLMs) have seen remarkable progress in recent years, transforming the landscape of artificial intelligence and natural language processing. In this post, we break down the technical reasons for this rapid improvement, with explanations and visual aids suitable for CS undergraduates and graduate-level researchers.</p> <h2 id="1-scaling-laws-and-model-size">1. Scaling Laws and Model Size</h2> <p>One of the most important discoveries in modern deep learning is the existence of <strong>scaling laws</strong>. Kaplan et al. (2020) showed that as you increase the number of model parameters, the amount of training data, and the compute budget, the performance of LLMs improves in a predictable, often log-linear fashion. This means that, up to a point, “bigger is better” for language models. <img src="./scaling_laws.png" alt="Scaling Laws for Neural Language Models"> </p> <p><em>Figure: Example scaling curve from <a href="https://arxiv.org/abs/2001.08361" rel="external nofollow noopener" target="_blank">Kaplan et al., 2020</a>.</em></p> <p>This insight led to the creation of models like GPT-3, GPT-4, and Gemini, which have hundreds of billions of parameters. These models can memorize more patterns, capture more nuanced relationships, and generalize better to new tasks.</p> <h2 id="2-improved-training-data-and-curation">2. Improved Training Data and Curation</h2> <p>The quality and diversity of training data are crucial. Early LLMs were trained on web scrapes with minimal filtering, but modern models use carefully curated datasets that include books, code, scientific papers, and multilingual content. For example, “The Pile” (<a href="https://arxiv.org/abs/2101.00027" rel="external nofollow noopener" target="_blank">Gao et al., 2020</a>) is an 800GB dataset designed to be both broad and high-quality. <img src="./pile.png" alt="The Pile Datase"> </p> <p><em>Figure: The Pile dataset is a diverse, high-quality resource for LLM training (<a href="https://arxiv.org/abs/2101.00027" rel="external nofollow noopener" target="_blank">Gao et al., 2020</a>).</em></p> <p>This diversity allows LLMs to answer questions about a wide range of topics, write code, and even reason about scientific problems.</p> <h2 id="3-advanced-training-techniques">3. Advanced Training Techniques</h2> <p>Modern LLMs are not just trained to predict the next word. Techniques like <strong>Reinforcement Learning from Human Feedback (RLHF)</strong> (<a href="https://arxiv.org/abs/2203.02155" rel="external nofollow noopener" target="_blank">Ouyang et al., 2022</a>) allow models to be fine-tuned based on human preferences, making their outputs more helpful and less toxic. <strong>Instruction tuning</strong> and <strong>chain-of-thought prompting</strong> (<a href="https://arxiv.org/abs/2201.11903" rel="external nofollow noopener" target="_blank">Wei et al., 2022</a>) further improve the ability of LLMs to follow complex instructions and reason step by step.</p> <p><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/b/b2/RLHF_diagram.svg/500px-RLHF_diagram.svg.png" alt="RLHF Diagram" style="max-width:400px; border:1px solid #eee; border-radius:8px; margin:1em 0;"></p> <p><em>Figure: RLHF pipeline for aligning LLMs with human preferences (<a href="https://arxiv.org/abs/2203.02155" rel="external nofollow noopener" target="_blank">Ouyang et al., 2022</a>).</em></p> <h2 id="4-architectural-innovations">4. Architectural Innovations</h2> <p>The <strong>Transformer</strong> architecture (<a href="https://arxiv.org/abs/1706.03762" rel="external nofollow noopener" target="_blank">Vaswani et al., 2017</a>) is the backbone of all modern LLMs. However, new ideas like <strong>sparse attention</strong> (which reduces compute by focusing only on relevant parts of the input), <strong>mixture-of-experts</strong> (<a href="https://arxiv.org/abs/1701.06538" rel="external nofollow noopener" target="_blank">Shazeer et al., 2017</a>), and <strong>retrieval-augmented generation</strong> (<a href="https://arxiv.org/abs/2112.04426" rel="external nofollow noopener" target="_blank">Borgeaud et al., 2022</a>) have made models faster and more efficient.</p> <p><img src="./transformers.png" alt="Transformer Architecture"> <em>Figure: The Transformer architecture is foundational for LLMs (<a href="https://arxiv.org/abs/1706.03762" rel="external nofollow noopener" target="_blank">Vaswani et al., 2017</a>).</em></p> <h2 id="5-better-evaluation-and-safety-practices">5. Better Evaluation and Safety Practices</h2> <p>As LLMs become more powerful, evaluating their capabilities and ensuring safety is critical. The community has developed robust benchmarks (e.g., MMLU, BIG-bench) and safety protocols to reduce harmful or biased outputs (<a href="https://openai.com/research/publications" rel="external nofollow noopener" target="_blank">OpenAI, 2023</a>). This includes adversarial testing, red-teaming, and continuous monitoring.</p> <p><img src="./image-1.png" alt="Big Bench Extra Hard benchmark"></p> <p><em>Figure: BIG-bench is a collaborative benchmark for evaluating LLMs (<a href="https://arxiv.org/pdf/2502.19187" rel="external nofollow noopener" target="_blank">BIG-bench Extra Hard, Google AI</a>).</em></p> <h2 id="conclusion">Conclusion</h2> <p>The rapid improvement of LLMs is driven by a combination of scaling, better data, advanced training, architectural innovation, and improved evaluation. Each of these factors is underpinned by technical advances and careful engineering. As research continues, we can expect even more capable and responsible language models in the near future.</p> <hr> <p><strong>References:</strong></p> <ul> <li>Kaplan, J., et al. (2020). Scaling Laws for Neural Language Models. <a href="https://arxiv.org/abs/2001.08361" rel="external nofollow noopener" target="_blank">arXiv:2001.08361</a> </li> <li>Gao, L., et al. (2020). The Pile: An 800GB Dataset of Diverse Text for Language Modeling. <a href="https://arxiv.org/abs/2101.00027" rel="external nofollow noopener" target="_blank">arXiv:2101.00027</a> </li> <li>Ouyang, L., et al. (2022). Training language models to follow instructions with human feedback. <a href="https://arxiv.org/abs/2203.02155" rel="external nofollow noopener" target="_blank">arXiv:2203.02155</a> </li> <li>Wei, J., et al. (2022). Chain-of-Thought Prompting Elicits Reasoning in Large Language Models. <a href="https://arxiv.org/abs/2201.11903" rel="external nofollow noopener" target="_blank">arXiv:2201.11903</a> </li> <li>Vaswani, A., et al. (2017). Attention is All You Need. <a href="https://arxiv.org/abs/1706.03762" rel="external nofollow noopener" target="_blank">arXiv:1706.03762</a> </li> <li>Shazeer, N., et al. (2017). Outrageously Large Neural Networks: The Sparsely-Gated Mixture-of-Experts Layer. <a href="https://arxiv.org/abs/1701.06538" rel="external nofollow noopener" target="_blank">arXiv:1701.06538</a> </li> <li>Borgeaud, S., et al. (2022). Improving language models by retrieving from trillions of tokens. <a href="https://arxiv.org/abs/2112.04426" rel="external nofollow noopener" target="_blank">arXiv:2112.04426</a> </li> <li>OpenAI. (2023). Research Publications. <a href="https://openai.com/research/publications" rel="external nofollow noopener" target="_blank">OpenAI</a> </li> </ul> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Ashish Sinha. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Last updated: September 02, 2025. </div> </footer> <script src="/assets/libs/jquery/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="/assets/libs/mdb/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="/assets/libs/masonry/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="/assets/libs/imagesloaded/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js?a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="/assets/libs/medium_zoom/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="/assets/libs/mathjax/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/assets/js/mathjax-setup.js?a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="/assets/libs/polyfill/polyfill.min.js" crossorigin="anonymous"></script> <script async src="https://www.googletagmanager.com/gtag/js?id=UA-98666071-1"></script> <script>
    window.dataLayer = window.dataLayer || [];
    function gtag() {
      dataLayer.push(arguments);
    }
    gtag('js', new Date());

    gtag('config', 'UA-98666071-1');
  </script> <script defer src="/assets/js/google-analytics-setup.js"></script> <script defer src="/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/assets/js/search-setup.js?6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/assets/js/search-data.js"></script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>