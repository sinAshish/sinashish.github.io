<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.4.1">Jekyll</generator><link href="https://sinashish.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://sinashish.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2025-09-02T14:29:53+00:00</updated><id>https://sinashish.github.io/feed.xml</id><title type="html">blank</title><subtitle>A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. </subtitle><entry><title type="html">How LLMs Are Getting Better and Better: Key Drivers of Progress</title><link href="https://sinashish.github.io/blog/2025/llms-are-getting-better/" rel="alternate" type="text/html" title="How LLMs Are Getting Better and Better: Key Drivers of Progress"/><published>2025-07-22T00:00:00+00:00</published><updated>2025-07-22T00:00:00+00:00</updated><id>https://sinashish.github.io/blog/2025/llms-are-getting-better</id><content type="html" xml:base="https://sinashish.github.io/blog/2025/llms-are-getting-better/"><![CDATA[<p>Large Language Models (LLMs) have seen remarkable progress in recent years, transforming the landscape of artificial intelligence and natural language processing. In this post, we break down the technical reasons for this rapid improvement, with explanations and visual aids suitable for CS undergraduates and graduate-level researchers.</p> <h2 id="1-scaling-laws-and-model-size">1. Scaling Laws and Model Size</h2> <p>One of the most important discoveries in modern deep learning is the existence of <strong>scaling laws</strong>. Kaplan et al. (2020) showed that as you increase the number of model parameters, the amount of training data, and the compute budget, the performance of LLMs improves in a predictable, often log-linear fashion. This means that, up to a point, “bigger is better” for language models. <img src="./scaling_laws.png" alt="Scaling Laws for Neural Language Models"/> </p> <p><em>Figure: Example scaling curve from <a href="https://arxiv.org/abs/2001.08361">Kaplan et al., 2020</a>.</em></p> <p>This insight led to the creation of models like GPT-3, GPT-4, and Gemini, which have hundreds of billions of parameters. These models can memorize more patterns, capture more nuanced relationships, and generalize better to new tasks.</p> <h2 id="2-improved-training-data-and-curation">2. Improved Training Data and Curation</h2> <p>The quality and diversity of training data are crucial. Early LLMs were trained on web scrapes with minimal filtering, but modern models use carefully curated datasets that include books, code, scientific papers, and multilingual content. For example, “The Pile” (<a href="https://arxiv.org/abs/2101.00027">Gao et al., 2020</a>) is an 800GB dataset designed to be both broad and high-quality. <img src="./pile.png" alt="The Pile Datase"/> </p> <p><em>Figure: The Pile dataset is a diverse, high-quality resource for LLM training (<a href="https://arxiv.org/abs/2101.00027">Gao et al., 2020</a>).</em></p> <p>This diversity allows LLMs to answer questions about a wide range of topics, write code, and even reason about scientific problems.</p> <h2 id="3-advanced-training-techniques">3. Advanced Training Techniques</h2> <p>Modern LLMs are not just trained to predict the next word. Techniques like <strong>Reinforcement Learning from Human Feedback (RLHF)</strong> (<a href="https://arxiv.org/abs/2203.02155">Ouyang et al., 2022</a>) allow models to be fine-tuned based on human preferences, making their outputs more helpful and less toxic. <strong>Instruction tuning</strong> and <strong>chain-of-thought prompting</strong> (<a href="https://arxiv.org/abs/2201.11903">Wei et al., 2022</a>) further improve the ability of LLMs to follow complex instructions and reason step by step.</p> <p><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/b/b2/RLHF_diagram.svg/500px-RLHF_diagram.svg.png" alt="RLHF Diagram" style="max-width:400px; border:1px solid #eee; border-radius:8px; margin:1em 0;"/></p> <p><em>Figure: RLHF pipeline for aligning LLMs with human preferences (<a href="https://arxiv.org/abs/2203.02155">Ouyang et al., 2022</a>).</em></p> <h2 id="4-architectural-innovations">4. Architectural Innovations</h2> <p>The <strong>Transformer</strong> architecture (<a href="https://arxiv.org/abs/1706.03762">Vaswani et al., 2017</a>) is the backbone of all modern LLMs. However, new ideas like <strong>sparse attention</strong> (which reduces compute by focusing only on relevant parts of the input), <strong>mixture-of-experts</strong> (<a href="https://arxiv.org/abs/1701.06538">Shazeer et al., 2017</a>), and <strong>retrieval-augmented generation</strong> (<a href="https://arxiv.org/abs/2112.04426">Borgeaud et al., 2022</a>) have made models faster and more efficient.</p> <p><img src="./transformers.png" alt="Transformer Architecture"/> <em>Figure: The Transformer architecture is foundational for LLMs (<a href="https://arxiv.org/abs/1706.03762">Vaswani et al., 2017</a>).</em></p> <h2 id="5-better-evaluation-and-safety-practices">5. Better Evaluation and Safety Practices</h2> <p>As LLMs become more powerful, evaluating their capabilities and ensuring safety is critical. The community has developed robust benchmarks (e.g., MMLU, BIG-bench) and safety protocols to reduce harmful or biased outputs (<a href="https://openai.com/research/publications">OpenAI, 2023</a>). This includes adversarial testing, red-teaming, and continuous monitoring.</p> <p><img src="./image-1.png" alt="Big Bench Extra Hard benchmark"/></p> <p><em>Figure: BIG-bench is a collaborative benchmark for evaluating LLMs (<a href="https://arxiv.org/pdf/2502.19187">BIG-bench Extra Hard, Google AI</a>).</em></p> <h2 id="conclusion">Conclusion</h2> <p>The rapid improvement of LLMs is driven by a combination of scaling, better data, advanced training, architectural innovation, and improved evaluation. Each of these factors is underpinned by technical advances and careful engineering. As research continues, we can expect even more capable and responsible language models in the near future.</p> <hr/> <p><strong>References:</strong></p> <ul> <li>Kaplan, J., et al. (2020). Scaling Laws for Neural Language Models. <a href="https://arxiv.org/abs/2001.08361">arXiv:2001.08361</a></li> <li>Gao, L., et al. (2020). The Pile: An 800GB Dataset of Diverse Text for Language Modeling. <a href="https://arxiv.org/abs/2101.00027">arXiv:2101.00027</a></li> <li>Ouyang, L., et al. (2022). Training language models to follow instructions with human feedback. <a href="https://arxiv.org/abs/2203.02155">arXiv:2203.02155</a></li> <li>Wei, J., et al. (2022). Chain-of-Thought Prompting Elicits Reasoning in Large Language Models. <a href="https://arxiv.org/abs/2201.11903">arXiv:2201.11903</a></li> <li>Vaswani, A., et al. (2017). Attention is All You Need. <a href="https://arxiv.org/abs/1706.03762">arXiv:1706.03762</a></li> <li>Shazeer, N., et al. (2017). Outrageously Large Neural Networks: The Sparsely-Gated Mixture-of-Experts Layer. <a href="https://arxiv.org/abs/1701.06538">arXiv:1701.06538</a></li> <li>Borgeaud, S., et al. (2022). Improving language models by retrieving from trillions of tokens. <a href="https://arxiv.org/abs/2112.04426">arXiv:2112.04426</a></li> <li>OpenAI. (2023). Research Publications. <a href="https://openai.com/research/publications">OpenAI</a></li> </ul>]]></content><author><name></name></author><category term="old-site"/><summary type="html"><![CDATA[Large Language Models (LLMs) have seen remarkable progress in recent years, transforming the landscape of artificial intelligence and natural language processing. In this post, we break down the technical reasons for this rapid improvement, with explanations and visual aids suitable for CS undergraduates and graduate-level researchers.]]></summary></entry><entry><title type="html">Welcome to read my random musings</title><link href="https://sinashish.github.io/blog/2025/welcome-to-my-blog/" rel="alternate" type="text/html" title="Welcome to read my random musings"/><published>2025-07-22T00:00:00+00:00</published><updated>2025-07-22T00:00:00+00:00</updated><id>https://sinashish.github.io/blog/2025/welcome-to-my-blog</id><content type="html" xml:base="https://sinashish.github.io/blog/2025/welcome-to-my-blog/"><![CDATA[<p>This is the first post on my blog. I used to write on <a href="https://medium.com/@ashish_sinha">Medium</a> a while back but haven’t written in a while. I want to start again, probably here, or on substack.</p> <p>But here is me…just testing some bindings below:</p> <p>Example:</p> <p>Inline math: $E=mc^2$</p> <p>Display math:</p> \[\int_{-\infty}^{\infty} e^{-x^2} dx = \sqrt{\pi}\] <p>Stay tuned for more updates!</p>]]></content><author><name></name></author><category term="old-site"/><summary type="html"><![CDATA[This is the first post on my blog. I used to write on Medium a while back but haven’t written in a while. I want to start again, probably here, or on substack.]]></summary></entry><entry><title type="html">a post with jupyter notebook</title><link href="https://sinashish.github.io/blog/2023/jupyter-notebook/" rel="alternate" type="text/html" title="a post with jupyter notebook"/><published>2023-07-04T12:57:00+00:00</published><updated>2023-07-04T12:57:00+00:00</updated><id>https://sinashish.github.io/blog/2023/jupyter-notebook</id><content type="html" xml:base="https://sinashish.github.io/blog/2023/jupyter-notebook/"><![CDATA[<p>To include a jupyter notebook in a post, you can use the following code:</p> <div class="language-liquid highlighter-rouge"><div class="highlight"><pre class="highlight"><code>{::nomarkdown}
<span class="cp">{%</span><span class="w"> </span><span class="nt">assign</span><span class="w"> </span><span class="nv">jupyter_path</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s1">'assets/jupyter/blog.ipynb'</span><span class="w"> </span><span class="p">|</span><span class="w"> </span><span class="nf">relative_url</span><span class="w"> </span><span class="cp">%}</span>
<span class="cp">{%</span><span class="w"> </span><span class="nt">capture</span><span class="w"> </span><span class="nv">notebook_exists</span><span class="w"> </span><span class="cp">%}{%</span><span class="w"> </span><span class="nt">file_exists</span><span class="w"> </span>assets/jupyter/blog.ipynb<span class="w"> </span><span class="cp">%}{%</span><span class="w"> </span><span class="nt">endcapture</span><span class="w"> </span><span class="cp">%}</span>
<span class="cp">{%</span><span class="w"> </span><span class="nt">if</span><span class="w"> </span><span class="nv">notebook_exists</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="s1">'true'</span><span class="w"> </span><span class="cp">%}</span>
  <span class="cp">{%</span><span class="w"> </span><span class="nt">jupyter_notebook</span><span class="w"> </span><span class="nv">jupyter_path</span><span class="w"> </span><span class="cp">%}</span>
<span class="cp">{%</span><span class="w"> </span><span class="nt">else</span><span class="w"> </span><span class="cp">%}</span>
  &lt;p&gt;Sorry, the notebook you are looking for does not exist.&lt;/p&gt;
<span class="cp">{%</span><span class="w"> </span><span class="nt">endif</span><span class="w"> </span><span class="cp">%}</span>
{:/nomarkdown}
</code></pre></div></div> <p>Let’s break it down: this is possible thanks to <a href="https://github.com/red-data-tools/jekyll-jupyter-notebook">Jekyll Jupyter Notebook plugin</a> that allows you to embed jupyter notebooks in your posts. It basically calls <a href="https://nbconvert.readthedocs.io/en/latest/usage.html#convert-html"><code class="language-plaintext highlighter-rouge">jupyter nbconvert --to html</code></a> to convert the notebook to an html page and then includes it in the post. Since <a href="https://jekyllrb.com/docs/configuration/markdown/">Kramdown</a> is the default Markdown renderer for Jekyll, we need to surround the call to the plugin with the <a href="https://kramdown.gettalong.org/syntax.html#extensions">::nomarkdown</a> tag so that it stops processing this part with Kramdown and outputs the content as-is.</p> <p>The plugin takes as input the path to the notebook, but it assumes the file exists. If you want to check if the file exists before calling the plugin, you can use the <code class="language-plaintext highlighter-rouge">file_exists</code> filter. This avoids getting a 404 error from the plugin and ending up displaying the main page inside of it instead. If the file does not exist, you can output a message to the user. The code displayed above outputs the following:</p> <div class="jupyter-notebook" style="position: relative; width: 100%; margin: 0 auto;"> <div class="jupyter-notebook-iframe-container"> <iframe src="/assets/jupyter/blog.ipynb.html" style="position: absolute; top: 0; left: 0; border-style: none;" width="100%" height="100%" onload="this.parentElement.style.paddingBottom = (this.contentWindow.document.documentElement.scrollHeight + 10) + 'px'"></iframe> </div> </div> <p>Note that the jupyter notebook supports both light and dark themes.</p>]]></content><author><name></name></author><category term="sample-posts"/><category term="formatting"/><category term="jupyter"/><summary type="html"><![CDATA[an example of a blog post with jupyter notebook]]></summary></entry></feed>